From 8badbb344656ade8c5272a957ea41ea0fa20cae1 Mon Sep 17 00:00:00 2001
From: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
Date: Tue, 11 Aug 2015 16:30:13 +0530
Subject: [PATCH 16/62] sched/numa: Remove the NUMA sched_feature

Variable sched_numa_balancing is available for both CONFIG_SCHED_DEBUG
and !CONFIG_SCHED_DEBUG. All code paths now check for
sched_numa_balancing. Hence remove sched_feat(NUMA).

Suggested-by: Ingo Molnar <mingo@kernel.org>
Signed-off-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>
Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
Cc: Linus Torvalds <torvalds@linux-foundation.org>
Cc: Mel Gorman <mgorman@suse.de>
Cc: Mike Galbraith <efault@gmx.de>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Rik van Riel <riel@redhat.com>
Cc: Thomas Gleixner <tglx@linutronix.de>
Link: http://lkml.kernel.org/r/1439290813-6683-4-git-send-email-srikar@linux.vnet.ibm.com
Signed-off-by: Ingo Molnar <mingo@kernel.org>
---
 kernel/sched/core.c     |  6 ------
 kernel/sched/features.h | 16 ----------------
 2 files changed, 22 deletions(-)

diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index ca665f8..e0bd88b 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -2120,12 +2120,6 @@ __read_mostly bool sched_numa_balancing;
 void set_numabalancing_state(bool enabled)
 {
 	sched_numa_balancing = enabled;
-#ifdef CONFIG_SCHED_DEBUG
-	if (enabled)
-		sched_feat_set("NUMA");
-	else
-		sched_feat_set("NO_NUMA");
-#endif /* CONFIG_SCHED_DEBUG */
 }
 
 #ifdef CONFIG_PROC_SYSCTL
diff --git a/kernel/sched/features.h b/kernel/sched/features.h
index e6fd23b..edf5902 100644
--- a/kernel/sched/features.h
+++ b/kernel/sched/features.h
@@ -72,21 +72,5 @@ SCHED_FEAT(RT_PUSH_IPI, true)
 SCHED_FEAT(FORCE_SD_OVERLAP, false)
 SCHED_FEAT(RT_RUNTIME_SHARE, true)
 SCHED_FEAT(LB_MIN, false)
-
 SCHED_FEAT(ATTACH_AGE_LOAD, true)
 
-/*
- * Apply the automatic NUMA scheduling policy. Enabled automatically
- * at runtime if running on a NUMA machine. Can be controlled via
- * numa_balancing=
- */
-#ifdef CONFIG_NUMA_BALANCING
-
-/*
- * NUMA will favor moving tasks towards nodes where a higher number of
- * hinting faults are recorded during active load balancing. It will
- * resist moving tasks towards nodes where a lower number of hinting
- * faults have been recorded.
- */
-SCHED_FEAT(NUMA,	true)
-#endif
-- 
1.9.1

